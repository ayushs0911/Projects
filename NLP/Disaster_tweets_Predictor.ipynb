{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORl17NkA+G3bIe3R+Z7KQo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushs0911/Projects/blob/main/Disaster_tweets_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem Statement \n",
        "Constructing a Deep Learning Classification model to predict which Tweets are about real disaster and which one aren't. \n"
      ],
      "metadata": {
        "id": "xVu70rlC1IQT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project Include tasks like :**\n",
        "- Downloading Text Dataset from Kaggle\n",
        "- Visualising Text data \n",
        "- Converting text into numbers using tokenization \n",
        "- Turning our tokenized text into an embedding \n",
        "- Building Deeplearning text models\n",
        "- Comparing performance of each \n",
        "- combining models into an Ensemble \n",
        "- Finding the most wrong predictions. \n"
      ],
      "metadata": {
        "id": "kTv4Uqcjytko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions \n",
        "I've made a series of helper functions which can be beneficial in various tasks. So instead of rewriting them again and again, I'll import [helper_functions.py](https://raw.githubusercontent.com/ayushs0911/Projects/main/helper_functions.py) file from github."
      ],
      "metadata": {
        "id": "rrOfTPpD1ISs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download helper functions script\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgxKUeikC5dG",
        "outputId": "8508afd9-e80c-4b0e-9db8-59367527cc29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-14 06:48:38--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-03-14 06:48:38 (116 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "id": "GeMDmgtZDHq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download a text dataset\n",
        "We'll be using the [Real or not?](https://www.kaggle.com/c/nlp-getting-started/data) dataset from kaggle which contains text-based Tweets about natural disasters. \n"
      ],
      "metadata": {
        "id": "q5mMzaWHDT64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip'\n",
        "\n",
        "unzip_data('nlp_getting_started.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LLsTwh4Es8S",
        "outputId": "4d12348d-6972-4212-c2e5-5d8627e5ba7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-14 06:48:43--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.202.128, 74.125.20.128, 74.125.197.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.202.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2023-03-14 06:48:43 (116 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzipping `nlp_getting_started.zip` gives the following 3 `.csv` files:\n",
        "- `sample_submission.csv` \n",
        "- `train.csv`\n",
        "- `test.csv`"
      ],
      "metadata": {
        "id": "9Ojl128tE_Wa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing a test dataset \n",
        "Right now text data samples are in the form of `.csv` files. For an easy way to make them visual, we can turn them into pandas DataFrames. \n"
      ],
      "metadata": {
        "id": "8taoKYv8H7K_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ItCidUshJGG4",
        "outputId": "c6353f78-89b7-4000-cad5-479cc5664b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-55a0a328-24e4-483e-92d7-9806de0ec51e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55a0a328-24e4-483e-92d7-9806de0ec51e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-55a0a328-24e4-483e-92d7-9806de0ec51e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-55a0a328-24e4-483e-92d7-9806de0ec51e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#shuffling training dataframe \n",
        "train_df_shuffled = train_df.sample(frac = 1, random_state = 42)\n",
        "train_df_shuffled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DtydLMpqJSen",
        "outputId": "e9a86509-a55b-456c-e99a-46132f327a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id      keyword               location  \\\n",
              "2644  3796  destruction                    NaN   \n",
              "2227  3185       deluge                    NaN   \n",
              "5448  7769       police                     UK   \n",
              "132    191   aftershock                    NaN   \n",
              "6845  9810       trauma  Montgomery County, MD   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-310741e2-0b9c-460d-a49a-83042756d46e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-310741e2-0b9c-460d-a49a-83042756d46e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-310741e2-0b9c-460d-a49a-83042756d46e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-310741e2-0b9c-460d-a49a-83042756d46e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "K7euQK1SJkPv",
        "outputId": "56fbfc2c-cfc1-4a89-c7a9-032956abb36a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e212c59e-ffac-4d62-a759-ea31249ce6d2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e212c59e-ffac-4d62-a759-ea31249ce6d2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e212c59e-ffac-4d62-a759-ea31249ce6d2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e212c59e-ffac-4d62-a759-ea31249ce6d2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Training data has a 'target' columns. \n",
        "- We'll write code to find patters in `'text'` columns of training dataset to predict `'target'` column. \n",
        "- Test dataset doesn't have a `'target'` column. "
      ],
      "metadata": {
        "id": "qSkMYTEjJrEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking how many examples of each class \n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On-bMUNNKDUH",
        "outputId": "ac714c4f-9d2d-4d76-c35c-c6d33671fd72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is a binary classification problem, which is fairly balanced too. About **60%** negative class (`target = 0`) and **40%** positive class (`target = 1`)<br>\n",
        "`1` = a real disaster tweet <br>\n",
        "`0` = not a real disaster tweet "
      ],
      "metadata": {
        "id": "wbmcZs4GKOUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many total samples?\n",
        "print(f\"Total Training samples : {len(train_df)}\")\n",
        "print(f\"Total Test Samples : {len(test_df)}\")\n",
        "print(f\"Total Samples : {len(train_df) + len(test_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TxOhJ9PKK3Y",
        "outputId": "2596e1cc-05f1-486b-d046-fcac171f2d67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Training samples : 7613\n",
            "Total Test Samples : 3263\n",
            "Total Samples : 10876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualising Random text samples"
      ],
      "metadata": {
        "id": "FELfl4I1LCWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random \n",
        "random_index = random.randint(0, len(train_df)-5) # creating indexes less than total samples\n",
        "for row in train_df_shuffled[['text', 'target']][random_index : random_index+5].itertuples():\n",
        "  _, text, target = row \n",
        "  print(f\"Target : {target}\", '(real disaster)' if target > 0 else '(not real disaster)')\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFbCmHcKzAay",
        "outputId": "be14fd84-21a3-419e-80fd-16f4574b9912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target : 0 (not real disaster)\n",
            "Text:\n",
            "R'lyeh by Upheaval http://t.co/829n4HJHOL\n",
            "\n",
            "---\n",
            "\n",
            "Target : 0 (not real disaster)\n",
            "Text:\n",
            "What if every 5000 wins in ranked play gave you a special card back.. Would be cool for the long teÛ_ http://t.co/vq3yaB2j8N\n",
            "\n",
            "---\n",
            "\n",
            "Target : 0 (not real disaster)\n",
            "Text:\n",
            "@indiepopmom I CANT BREATHE MY LUNGS COLLAPSED\n",
            "\n",
            "---\n",
            "\n",
            "Target : 1 (real disaster)\n",
            "Text:\n",
            "Fire in Pisgah National Forest grows to 375 acres http://t.co/dao9AZEUcr\n",
            "\n",
            "---\n",
            "\n",
            "Target : 0 (not real disaster)\n",
            "Text:\n",
            "@pjcoyle ... need to be included in emergency planning for chemical plants. See also http://t.co/OamqqBNIce\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting data into training and Validation sets \n",
        "- Since test set has no labels, we need a way to evaluate our trained models, we'll splot off some of training data and create a validation set. \n",
        "- When our model trains, it'll only see data from training set and we can see how it performs on unseen data using validation set. \n",
        "- Converting our splits from pandas Series datatypes to lists of strings(for the text) and lists of ints(for the labels). \n",
        "\n",
        "To split our training dataset, we'll use Scikit-Learn's `train_test_split()` method and dedicate 10% of training samples to validation set. "
      ],
      "metadata": {
        "id": "UsKhVjyR0D4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_sentances, val_sentances, train_labels, val_labels = train_test_split(train_df_shuffled['text'].to_numpy(),\n",
        "                                                                            train_df_shuffled['target'].to_numpy(),\n",
        "                                                                            test_size = 0.1,\n",
        "                                                                            random_state = 42)"
      ],
      "metadata": {
        "id": "lPPbThml1IXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the lengths\n",
        "len(train_sentances), len(train_labels), len(val_sentances), len(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kKAOxzI1mTo",
        "outputId": "e984eeb5-ff8f-427d-df92-eba87e95ebe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentances[:5], train_labels[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSdV-BOp1oA3",
        "outputId": "836d02ec-887f-40fe-d827-0e1fbbe383ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting text into numbers\n",
        "\n",
        "In NLP, there are two main concepts for turning text into numbers: \n",
        "- **Tokenization** : A straight mapping from word or character or sub-word to a numerical value. There are three main levels of tokenization :\n",
        "  - Word-level tokenization \n",
        "  - Character-level tokenization\n",
        "  - Sub-word tokenization\n",
        "- **Embeddings** :  An embedding is a representation of natural language which can be learned. Representation comes in the form of a feature vector. The size of the feature vector is tuneable. There are two ways to use embeddings:\n",
        "  - Create your own embedding \n",
        "  - Reuse a pre-learned embedding \n",
        "\n"
      ],
      "metadata": {
        "id": "AImiPRTS2BO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Vectorization (tokenization)\n",
        "To Tokenize our words, we'll use the preprocessing layer `tf.keras.layers.experimental.preprocessing.TextVectorization`\n"
      ],
      "metadata": {
        "id": "yTVRwPwv441S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "metadata": {
        "id": "WBh1BDzv5Vpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For `max_tokens` (number of worjds in the vocabulary), multiples of 10,000(`10,000`, `20,000`, `30,000`) or exact number of unique words in text are common values. <br>\n",
        "For our use case, we'll use `10,000`. <br>\n",
        "For the `output_sequence_length` we'll use average number of tokens per Tweet in training set. To find it :"
      ],
      "metadata": {
        "id": "HIUxokJ15-8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "round(sum([len(i.split()) for i in train_sentances])/len(train_sentances))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_pkg7q7701a",
        "outputId": "f18a1638-a048-4fe5-f107-31545af76817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting up text vectorization \n",
        "max_vocab_length = 10000 #max no. of words to have in vocabulary \n",
        "max_length = 15 # max length our sequences\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens = max_vocab_length,\n",
        "                                    output_mode = 'int',\n",
        "                                    output_sequence_length = max_length)"
      ],
      "metadata": {
        "id": "opWdKj7N8OJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To map our `TextVectorization` instance `text_vectorizer` to our data, we call the `adapt()` method on it whilst passing it out training text. "
      ],
      "metadata": {
        "id": "gwt5kt4P84C2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorizer.adapt(train_sentances)"
      ],
      "metadata": {
        "id": "7PJXVNHB9VTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying `text_vectorizer` on few random sentanaces. "
      ],
      "metadata": {
        "id": "zGjZGYQE9avn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#choosing a random sentance from training dataset and tokenize it \n",
        "random_sentance = random.choice(train_sentances)\n",
        "print(f\"Original text:\\n {random_sentance}\\\n",
        "\\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentance])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q91KtwAb9v7i",
        "outputId": "323f581f-50ca-46b8-d671-c463b6e55e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " I'm that traumatised that I can't even spell properly! Excuse the typos!\n",
            "\n",
            "Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[  32,   16,  412,   16,    8,   98,  151, 8232, 9531, 5692,    2,\n",
              "        4353,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the unique tokens in our vocabulary using the `get_vocabulary()` method. "
      ],
      "metadata": {
        "id": "iGzmhP0I-5h_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f\"Number of words in vocab : {len(words_in_vocab)}\")\n",
        "print(f\"Bottom 5 common words : {words_in_vocab[-5:]}\")\n",
        "print(f\"Top 5 common words : {words_in_vocab[:5]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Hd0Xs_4_Y7j",
        "outputId": "11e1737f-6974-4bd9-e866-17c077698aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab : 10000\n",
            "Bottom 5 common words : ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n",
            "Top 5 common words : ['', '[UNK]', 'the', 'a', 'in']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating an Embedding using an Embedding layer \n",
        "The powerful thing about an embedding it it can be learned during training. This means rather than just being static, a word's numeric representation can be improved as a model goes through data samples. <br>\n",
        "Using `tf.keras.Embedding` layer :"
      ],
      "metadata": {
        "id": "q8dfAEH2AT_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "embedding = layers.Embedding(input_dim = max_vocab_length, #set input shape\n",
        "                             output_dim = 128, #set size of embedding layer\n",
        "                             embeddings_initializer = 'uniform',\n",
        "                             input_length = max_length,\n",
        "                             name = 'embedding_1')"
      ],
      "metadata": {
        "id": "KJ_D1VopBFRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling a text dataset \n",
        "We are going to build a series of different models, and then compare results of each model and see which one performed best. \n",
        "- Model 1 : Feed-Forward neural network\n",
        "- Model 2 : LSTM model \n",
        "- Model 3 : GRU model \n",
        "- Model 4 : Bidirectional-LSTM model \n",
        "- Model 5 : 1D Convolutional Neural Network \n",
        "- Model 6 : TensorFlow Hub Pretrained Feature Extractor \n",
        "\n"
      ],
      "metadata": {
        "id": "RHh34Q8FCAL5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating an evaluation function for our model experiments \n",
        "We are going to evaluate a number of models, let's create a helper function which takes an array of predictions and ground truth labels and computes :\n",
        "- Accuracy \n",
        "- Precision \n",
        "- Recall \n",
        "- F1-score.  "
      ],
      "metadata": {
        "id": "_6TqtELXEeAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "def calculate_results(y_true, y_pred):\n",
        "  model_accuracy = accuracy_score(y_true, y_pred)*100\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average = 'weighted')\n",
        "  model_results = {'accuracy' : model_accuracy,\n",
        "                   'precision' : model_precision,\n",
        "                   'recall' : model_recall,\n",
        "                   'f1': model_f1}\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "jI1bx1514IQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1 : A simple dense model "
      ],
      "metadata": {
        "id": "74OFUXWK42Fh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "#directory to save Tensorboard logs \n",
        "SAVE_DIR = 'model_logs'"
      ],
      "metadata": {
        "id": "mBINkgFk5AWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Building model with Functional API \n",
        "from tensorflow.keras import layers \n",
        "inputs = layers.Input(shape =(1,), dtype = 'string') #inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) #converting text into numbers\n",
        "x = embedding(x) #embedding of numericals\n",
        "x = layers.GlobalAveragePooling1D()(x) #lower the dimensionality of the embedding \n",
        "outputs = layers.Dense(1, activation = 'sigmoid')(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs, name = 'model_1_dense')\n",
        "\n",
        "#compile the model\n",
        "model_1.compile(loss = 'binary_crossentropy',\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])\n"
      ],
      "metadata": {
        "id": "PaYTRszc5mi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b52SCLtxE3DO",
        "outputId": "f5b50070-c66d-4ed1-e269-0f3693570917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d_1   (None, 128)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_history = model_1.fit(train_sentances,\n",
        "                              train_labels,\n",
        "                              epochs = 5,\n",
        "                              validation_data = (val_sentances, val_labels),\n",
        "                              callbacks = [create_tensorboard_callback(dir_name = SAVE_DIR, \n",
        "                                                                       experiment_name = 'simple_dense_model')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-GdUJZq6rR0",
        "outputId": "e7d14989-c2f7-4d32-de19-52cca44a2f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/simple_dense_model/20230314-070248\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 14ms/step - loss: 0.6103 - accuracy: 0.6981 - val_loss: 0.5343 - val_accuracy: 0.7703\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.4420 - accuracy: 0.8202 - val_loss: 0.4699 - val_accuracy: 0.7861\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.3467 - accuracy: 0.8597 - val_loss: 0.4559 - val_accuracy: 0.7913\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.2836 - accuracy: 0.8913 - val_loss: 0.4655 - val_accuracy: 0.7927\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.2372 - accuracy: 0.9104 - val_loss: 0.4785 - val_accuracy: 0.7900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check model's performance on validation set. "
      ],
      "metadata": {
        "id": "Cb0CaPcP7b49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.evaluate(val_sentances, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbMtaD5v7rNV",
        "outputId": "d35ab87c-ecfe-46bd-cae5-fa056d3711a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.47845780849456787, 0.7900262475013733]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#making predictions \n",
        "model_1_pred_probs = model_1.predict(val_sentances)\n",
        "\n",
        "#convert prediction probabilties to prediction classes \n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs)) #removing the extra dimension"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31UGp22C7u1Y",
        "outputId": "7fa2a01a-255d-4fb4-b91a-d920b09ed3cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results = calculate_results(y_true = val_labels, \n",
        "                                    y_pred = model_1_preds)\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NugWCSc8O6b",
        "outputId": "99f596b6-30f5-4233-f829-8f52487f063b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.00262467191601,\n",
              " 'precision': 0.7955103864713003,\n",
              " 'recall': 0.7900262467191601,\n",
              " 'f1': 0.7869273549752186}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2 : LSTM \n",
        "We'll use `tensorflow.keras.layers.LSTM()`. <br>\n",
        "And to make sure we are not reusing trained embeddings (this would cause data leakage between models, leading to uneven comparisons) for our model.  "
      ],
      "metadata": {
        "id": "Lq2D70Sh8380"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#new embedding layer\n",
        "model_2_embedding = layers.Embedding(input_dim = max_vocab_length, \n",
        "                                      output_dim = 128,\n",
        "                                      embeddings_initializer = 'uniform',\n",
        "                                      input_length = max_length,\n",
        "                                      name = 'embedding_2')\n",
        "\n",
        "\n",
        "#Create LSTM model \n",
        "inputs = layers.Input(shape = (1,), dtype = 'string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_2_embedding(x)\n",
        "x = layers.LSTM(64)(x)\n",
        "x = layers.Dense(64, activation = 'relu')(x)\n",
        "outputs = layers.Dense(1, activation = 'sigmoid')(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name = 'model_2_LSTM')\n",
        "\n",
        "# compile the model \n",
        "model_2.compile(loss='binary_crossentropy',\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "bocQjzKEDiSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoM7ex1iEdmw",
        "outputId": "dec6f056-6759-46d5-bbfd-7dd80acbde12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,333,633\n",
            "Trainable params: 1,333,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model\n",
        "model_2_history = model_2.fit(train_sentances,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentances, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     \"LSTM\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWBajumdE8Ro",
        "outputId": "d7a631b7-fb10-455b-b0cc-5862f38a4a38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/LSTM/20230314-074547\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 23ms/step - loss: 0.5116 - accuracy: 0.7484 - val_loss: 0.4637 - val_accuracy: 0.7743\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.3164 - accuracy: 0.8708 - val_loss: 0.4882 - val_accuracy: 0.7743\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.2151 - accuracy: 0.9153 - val_loss: 0.6178 - val_accuracy: 0.7703\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 5s 22ms/step - loss: 0.1411 - accuracy: 0.9463 - val_loss: 0.8059 - val_accuracy: 0.7690\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.1015 - accuracy: 0.9569 - val_loss: 0.9884 - val_accuracy: 0.7664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_pred_probs = model_2.predict(val_sentances)\n",
        "\n",
        "#convert prediction probabilties to prediction classes \n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_DaOHi3FGrf",
        "outputId": "19a9a008-e915-4670-9286-3c3ef096a588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate LSTM model results \n",
        "model_2_results = calculate_results(y_true = val_labels, \n",
        "                                    y_pred = model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlKhBFwPF8uM",
        "outputId": "4a75a1b5-fe39-4f7f-c9e4-6cfd31b08e13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.64041994750657,\n",
              " 'precision': 0.7676724239336781,\n",
              " 'recall': 0.7664041994750657,\n",
              " 'f1': 0.7644156046177798}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3 : GRU \n",
        "Another effective RNN component is. GRU or Gated recurrent unit. <br>\n",
        "The GRU cell has similar structure features to LSTM cell but has less parameters. <br>\n",
        "Using `tensorflow.keras.layers.GRU()` class. "
      ],
      "metadata": {
        "id": "iQuycYitGlFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_embedding = layers.Embedding(input_dim = max_vocab_length,\n",
        "                                     output_dim = 128,\n",
        "                                     embeddings_initializer = 'uniform',\n",
        "                                     input_length = max_length,\n",
        "                                     name = 'embedding_3')\n",
        "# Build an RNN using GRU cell \n",
        "inputs = layers.Input(shape = (1,), dtype = 'string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_3_embedding(x)\n",
        "x = layers.GRU(64)(x)\n",
        "x = layers.Dense(64, activation ='relu')(x)\n",
        "outputs = layers.Dense(1, activation = 'sigmoid')(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name = 'model_3_GRU')\n",
        "\n",
        "# Compile GRU model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit model\n",
        "model_3_history = model_3.fit(train_sentances,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentances, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"GRU\")])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0MrJ9SWHRqk",
        "outputId": "f9521586-2aad-4eb7-926e-db47c3eaa69b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/GRU/20230314-080209\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 21ms/step - loss: 0.5277 - accuracy: 0.7292 - val_loss: 0.4609 - val_accuracy: 0.7861\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.3232 - accuracy: 0.8694 - val_loss: 0.4643 - val_accuracy: 0.7900\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.2223 - accuracy: 0.9167 - val_loss: 0.6323 - val_accuracy: 0.7664\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.1606 - accuracy: 0.9396 - val_loss: 0.6343 - val_accuracy: 0.7585\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.1193 - accuracy: 0.9568 - val_loss: 0.7049 - val_accuracy: 0.7690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkknYz_CIzqN",
        "outputId": "e878355f-5d71-4681-898f-124dcddc5117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,473\n",
            "Trainable params: 1,321,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions on validation data\n",
        "model_3_pred_probs = model_3.predict(val_sentances)\n",
        "\n",
        "#convert prediction probabilties to prediction classes \n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nlHYN3XJE9p",
        "outputId": "9e46450e-6657-4f9f-a5fc-709588ece123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcuate model_3 results\n",
        "model_3_results = calculate_results(y_true=val_labels, \n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITDMcxa9JlOq",
        "outputId": "9646711a-cbd0-4b34-cc6a-3f77b78d2b82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.9028871391076,\n",
              " 'precision': 0.7692529451017919,\n",
              " 'recall': 0.7690288713910761,\n",
              " 'f1': 0.7677604393034507}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4 : Bidirectional RNN Model \n",
        "A Standard RNN will process a sequence from left to right, where as Bidirectional RNN will process the sequence from left to right and then again from right to left. <br>\n",
        "We'll use `tensorflow.keras.layers.Bidirectional`\n"
      ],
      "metadata": {
        "id": "wBIuSwiHJtLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# new embedding layer \n",
        "model_4_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_4\")\n",
        "\n",
        "# Build a Bidirectional RNN in TensorFlow\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_4_embedding(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x) # bidirectional goes both ways so has double the parameters of a regular LSTM layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")\n",
        "\n",
        "# Compile\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model (takes longer because of the bidirectional layers)\n",
        "model_4_history = model_4.fit(train_sentances,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentances, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"bidirectional_RNN\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaB_x75aKrTx",
        "outputId": "f0bb4ee3-78c0-4a29-88f8-598ee3cbf8ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/bidirectional_RNN/20230314-081141\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 29ms/step - loss: 0.5083 - accuracy: 0.7501 - val_loss: 0.4561 - val_accuracy: 0.7822\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 6s 28ms/step - loss: 0.3137 - accuracy: 0.8673 - val_loss: 0.4826 - val_accuracy: 0.7808\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 5s 24ms/step - loss: 0.2065 - accuracy: 0.9225 - val_loss: 0.5690 - val_accuracy: 0.7690\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 6s 28ms/step - loss: 0.1403 - accuracy: 0.9502 - val_loss: 0.8281 - val_accuracy: 0.7651\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 5s 24ms/step - loss: 0.0996 - accuracy: 0.9651 - val_loss: 0.9188 - val_accuracy: 0.7520\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of our bidirectional model\n",
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-N3zoo7LMoG",
        "outputId": "bdab9075-88df-49ca-aaf2-b370a0d6ebb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_Bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_pred_probs = model_4.predict(val_sentances)\n",
        "\n",
        "# Convert prediction probabilities to labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYx6HacYLP3B",
        "outputId": "be414bf6-9316-4994-a010-9d20d9dfca4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate bidirectional RNN model results\n",
        "model_4_results = calculate_results(val_labels, model_4_preds)\n",
        "model_4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWK45iwqLjs4",
        "outputId": "db1f24d5-05aa-4f6f-91fc-34fabdea10e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.19685039370079,\n",
              " 'precision': 0.7548521446853059,\n",
              " 'recall': 0.7519685039370079,\n",
              " 'f1': 0.7487310335449245}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 5 : Conv1D"
      ],
      "metadata": {
        "id": "RgYOJg1gLmIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#new embedding layer \n",
        "from tensorflow.keras import layers\n",
        "model_5_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_5\")\n",
        "\n",
        "# Create 1-dimensional convolutional layer to model sequences\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_5_embedding(x)\n",
        "x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x)  \n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
        "\n",
        "# Compile Conv1D model\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_5_history = model_5.fit(train_sentances,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentances, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     \"Conv1D\")])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCKv81IWMF2P",
        "outputId": "fce6119a-63aa-452e-f82e-15d6a6a71ee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20230314-083018\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 14ms/step - loss: 0.5659 - accuracy: 0.7101 - val_loss: 0.4735 - val_accuracy: 0.7900\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.3465 - accuracy: 0.8575 - val_loss: 0.4748 - val_accuracy: 0.7900\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.2174 - accuracy: 0.9221 - val_loss: 0.5328 - val_accuracy: 0.7703\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.1376 - accuracy: 0.9543 - val_loss: 0.6276 - val_accuracy: 0.7677\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.0983 - accuracy: 0.9688 - val_loss: 0.6881 - val_accuracy: 0.7625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwk7cgYiPMGf",
        "outputId": "799d4848-63d7-4736-cca6-7568dac35fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 11, 32)            20512     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 32)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,300,545\n",
            "Trainable params: 1,300,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with model_5\n",
        "model_5_pred_probs = model_5.predict(val_sentances)\n",
        "\n",
        "# Convert model_5 prediction probabilities to labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha6dsZRsPNB8",
        "outputId": "2a14a8dd-b959-4bbc-b6db-36f7b1ad47ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_5 evaluation metrics \n",
        "model_5_results = calculate_results(y_true=val_labels, \n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmnOuLvMPU6w",
        "outputId": "34c55d1e-eff9-4e04-a7e9-db9744ba9ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.24671916010499,\n",
              " 'precision': 0.7639905060800456,\n",
              " 'recall': 0.7624671916010499,\n",
              " 'f1': 0.7602456873168202}"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 6: TensorFlow Hub Pretrained Sentence Encoder\n",
        "\n",
        "The main difference between the embedding layer we created and the Universal Sentence Encoder is that rather than create a word-level embedding, the Universal Sentence Encoder, creates a whole sentence-level embedding.\n",
        "\n",
        "Our embedding layer also outputs an a 128 dimensional vector for each word, where as, the Universal Sentence Encoder outputs a 512 dimensional vector for each sentence.<br>\n",
        "We can load in TensorFlow hub module using `hub.load()` method and passing it the target url of the module. "
      ],
      "metadata": {
        "id": "zKjBrvltPWyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading universal sentance encoder\n",
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # load Universal Sentence Encoder\n",
        "embed_samples = embed([\"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
        "\n",
        "print(embed_samples[0][:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G144rAXYQQcF",
        "outputId": "f51c4e4f-4772-4dd0-ba4f-740bcf7f59ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[ 0.03596691 -0.08579469 -0.01152743  0.00525982 -0.01852172 -0.05042012\n",
            " -0.03616941  0.00534677  0.04805917  0.04690744 -0.0372333  -0.01149546\n",
            "  0.04352415  0.07050991  0.0709376  -0.08180431  0.00871717 -0.04654121\n",
            " -0.02245776  0.04686872  0.00202256  0.03099072  0.02043563  0.06392168\n",
            " -0.07641086  0.08421179 -0.04576042 -0.00106165 -0.02059416  0.01241106\n",
            "  0.05727539  0.0381562  -0.02742118 -0.00354347 -0.09832586 -0.01244854\n",
            "  0.0386563   0.05031953 -0.02362506  0.00321848  0.03225209  0.00738095\n",
            "  0.04473104 -0.00412236  0.01151601  0.02837724  0.00060139 -0.05903354\n",
            " -0.00494347 -0.00688527], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_samples.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgfehGtgQxUV",
        "outputId": "30bd5a35-b05f-42ba-b2c0-683cc7650742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can convert the TensorFlow hub USE module into a Keras layer usisng the `hub.kerasLayer` class"
      ],
      "metadata": {
        "id": "kGnx9mlEQ_09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentance_encoded_layer = hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4',\n",
        "                                        input_shape = [],\n",
        "                                        dtype = tf.string,\n",
        "                                        trainable = False, \n",
        "                                        name = 'USE')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVE0SiTVRScN",
        "outputId": "a6426f6c-5ed7-49bd-d36c-c50a4df73573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating model using Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "    sentance_encoded_layer,\n",
        "    layers.Dense(64, activation = 'relu'),\n",
        "    layers.Dense(1, activation = 'sigmoid')\n",
        "], name = 'model_6_USE')\n",
        "\n",
        "# Compile model\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Train a classifier on top of pretrained embeddings\n",
        "model_6_history = model_6.fit(train_sentances,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentances, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     \"tf_hub_sentence_encoder\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg2JYpmDRsBb",
        "outputId": "16a9556a-6a9d-48e8-b11a-1cfbc73601a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20230314-084231\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 10ms/step - loss: 0.5102 - accuracy: 0.7825 - val_loss: 0.4456 - val_accuracy: 0.8005\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.4145 - accuracy: 0.8151 - val_loss: 0.4365 - val_accuracy: 0.8045\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.4015 - accuracy: 0.8189 - val_loss: 0.4312 - val_accuracy: 0.8097\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.3931 - accuracy: 0.8256 - val_loss: 0.4308 - val_accuracy: 0.8150\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.3853 - accuracy: 0.8297 - val_loss: 0.4286 - val_accuracy: 0.8163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKNpB41SSQRK",
        "outputId": "104057b1-5a85-42d2-8b92-e58b9467e0d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Number of paramters in the USE layer are the pretrained weights, learned on various text sources (Wikipedia, web news, web question-answer forums, etc).\n",
        "\n",
        "The trainable parameters are only in our output layers, in other words, we're keeping the USE weights frozen and using it as a feature-extractor. We could fine-tune these weights by setting `trainable=True` when creating the `hub.KerasLayer` instance."
      ],
      "metadata": {
        "id": "EpO1EHiPSVzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with USE TF Hub model\n",
        "model_6_pred_probs = model_6.predict(val_sentances)\n",
        "# Convert prediction probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMKFZDTiSs1O",
        "outputId": "5f3f5b29-0c8e-4bd7-8428-11fc772cd86d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model 6 performance metrics\n",
        "model_6_results = calculate_results(val_labels, model_6_preds)\n",
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8mjKrUoSyGy",
        "outputId": "d1d9b955-1661-4af9-e58d-72c20a7c3780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.62729658792651,\n",
              " 'precision': 0.818446310697231,\n",
              " 'recall': 0.8162729658792651,\n",
              " 'f1': 0.8148082644367335}"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing the performance of each our models\n",
        "To Visualise our model's performance, let's create a pandas DataFrame from our results dictionaries and then plot it. \n"
      ],
      "metadata": {
        "id": "iq8vxuTFS0mJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Combine model results into a DataFrame\n",
        "all_model_results = pd.DataFrame({'simple_dense': model_1_results,\n",
        "                                 'lstm' : model_2_results,\n",
        "                                 'gru' : model_3_results,\n",
        "                                 'bidirectional' : model_4_results,\n",
        "                                 'conv1d' : model_5_results,\n",
        "                                 'tf_hub_setance_encoder' : model_6_results})\n",
        "all_model_results = all_model_results.transpose()"
      ],
      "metadata": {
        "id": "perE8JHAwi1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reducing the accuracy to same scale as other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100\n",
        "all_model_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "T8EMbvYVw_r9",
        "outputId": "7fcd6b61-1e4c-4601-ebe9-8bb118a977b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        accuracy  precision    recall        f1\n",
              "simple_dense            0.790026   0.795510  0.790026  0.786927\n",
              "lstm                    0.766404   0.767672  0.766404  0.764416\n",
              "gru                     0.769029   0.769253  0.769029  0.767760\n",
              "bidirectional           0.751969   0.754852  0.751969  0.748731\n",
              "conv1d                  0.762467   0.763991  0.762467  0.760246\n",
              "tf_hub_setance_encoder  0.816273   0.818446  0.816273  0.814808"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b6d3b08-df56-41f9-bccd-f74a1b756b77\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>simple_dense</th>\n",
              "      <td>0.790026</td>\n",
              "      <td>0.795510</td>\n",
              "      <td>0.790026</td>\n",
              "      <td>0.786927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.767672</td>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.764416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>0.769029</td>\n",
              "      <td>0.769253</td>\n",
              "      <td>0.769029</td>\n",
              "      <td>0.767760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>0.751969</td>\n",
              "      <td>0.754852</td>\n",
              "      <td>0.751969</td>\n",
              "      <td>0.748731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conv1d</th>\n",
              "      <td>0.762467</td>\n",
              "      <td>0.763991</td>\n",
              "      <td>0.762467</td>\n",
              "      <td>0.760246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_setance_encoder</th>\n",
              "      <td>0.816273</td>\n",
              "      <td>0.818446</td>\n",
              "      <td>0.816273</td>\n",
              "      <td>0.814808</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b6d3b08-df56-41f9-bccd-f74a1b756b77')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5b6d3b08-df56-41f9-bccd-f74a1b756b77 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5b6d3b08-df56-41f9-bccd-f74a1b756b77');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "iU6uGYqBxLfj",
        "outputId": "95f85c9c-67d9-497d-a8d6-6c4cbb8c3fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like Pre-trained USE Tensorflow Hub model have best performance. "
      ],
      "metadata": {
        "id": "DmrSQIMZxXhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sort model results by f1-score \n",
        "all_model_results.sort_values('f1', ascending = False)['f1'].plot(kind = 'bar', figsize = (10,7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "qR0qd6kqx4uB",
        "outputId": "9e7df54c-adc4-4796-89c5-5187d136122e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making predictions on the test dataset\n",
        "We don't have labels for the test dataset so we're going to have to make some predictions and inspect them for ourselves."
      ],
      "metadata": {
        "id": "XNgm81xnyxDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#making predictions on test dataset \n",
        "test_sentances = test_df['text'].to_list()\n",
        "test_samples = random.sample(test_sentances, 10)\n",
        "for test_sample in test_samples:\n",
        "  pred_prob = tf.squeeze(model_6.predict([test_sample]))\n",
        "  pred = tf.round(pred_prob)\n",
        "  print(f\"Pred : {int(pred)}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{test_sample}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzMqpnoAzk2-",
        "outputId": "a81155df-8368-4043-c345-93c2ae87d025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 336ms/step\n",
            "Pred : 1, Prob: 0.7563539147377014\n",
            "Text:\n",
            "I'm security so they want me to help out in case of emergency like the buildings on fire or a shooter's in the building. I'm leaving tho..\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 177ms/step\n",
            "Pred : 0, Prob: 0.2631556987762451\n",
            "Text:\n",
            "MGS4 came out during a time of great upheaval in my life and itÛªs very odd that MGSV is coming and itÛªs also when things are getting iffy\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Pred : 0, Prob: 0.12955081462860107\n",
            "Text:\n",
            "Enjoying the shade under this tree. The sun is blazing but there is a cool breeze. @ West Hollywood Park https://t.co/2wzHj0lNa6\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "Pred : 0, Prob: 0.1443932205438614\n",
            "Text:\n",
            "@SheriffClarke @FreeAmerican100 If a carpenter built your house and it collapsed would you ask the same carpenter to rebuild it?\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "Pred : 1, Prob: 0.9421486258506775\n",
            "Text:\n",
            "#WAwildfire in #chelan? Wolverine fire results in evacuation. http://t.co/yePlnZPoWu\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 135ms/step\n",
            "Pred : 0, Prob: 0.1286291629076004\n",
            "Text:\n",
            "I'm proud of my heart it's been played stabbed cheated burned and broken. But somehow still works\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "Pred : 1, Prob: 0.9235711693763733\n",
            "Text:\n",
            "Man faces manslaughter charges following fatal Sunday wreck | AL.c.. Related Articles: http://t.co/5xrFhdXTvX\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Pred : 1, Prob: 0.5407199859619141\n",
            "Text:\n",
            "Morning Metro Late train? Check. Crazy guy who tells people the doors will electrocute them? Check.\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Pred : 1, Prob: 0.9911086559295654\n",
            "Text:\n",
            "#???? #?? #??? #??? Udhampur terror attack: Militants attack police post 2 SPOs injured - Times of   http://t.co/1KxsGlsTA7\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Pred : 0, Prob: 0.041665539145469666\n",
            "Text:\n",
            "Why are you deluged with low self-image? Take the quiz: http://t.co/JCaGECQFH2 http://t.co/nH313ADkz4\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
